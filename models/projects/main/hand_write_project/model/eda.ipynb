{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "- Numpy\n",
    "- os\n",
    "- tensorflow\n",
    "- time\n",
    "- Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.set_random_seed(404)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Variables\n",
    "\n",
    "- X Train\n",
    "- X Test\n",
    "- Y Train\n",
    "- Y Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'data/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'data/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'data/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'data/digit_ytest.csv'\n",
    "\n",
    "LOGGING_PATH = 'hw_logs/'\n",
    "\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH*IMAGE_HEIGHT*CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "\n",
    "- Testing the data\n",
    "- CPU Load Times\n",
    "- Shape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.6 ms, sys: 1.84 ms, total: 51.4 ms\n",
      "Wall time: 53.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 401 ms, total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "- Convert target values to one-hot encoding\n",
    "- Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale\n",
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target values to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = y_train_all[:5]\n",
    "np.eye(10)[values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(10)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "y_train_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.eye(NR_CLASSES)[y_test]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Graph\n",
    "\n",
    "- Neural Network Architecture\n",
    "- Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, TOTAL_INPUTS], name='X')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, NR_CLASSES], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_layer(input, weight_dim, bias_dim, name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
    "        w = tf.Variable(initial_value=initial_w, name='W')\n",
    "\n",
    "        initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
    "        b = tf.Variable(initial_value=initial_b, name='B')\n",
    "\n",
    "        layer_in = tf.matmul(input, w) + b\n",
    "        \n",
    "        if name=='out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "        \n",
    "        tf.summary.histogram('weights', w)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        \n",
    "        return layer_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1], \n",
    "                      bias_dim=[n_hidden1], name='layer_1')\n",
    "\n",
    "layer_drop = tf.nn.dropout(layer_1, rate=0.8, name='dropout_layer')\n",
    "\n",
    "layer_2 = setup_layer(layer_drop, weight_dim=[n_hidden1, n_hidden2], \n",
    "                      bias_dim=[n_hidden2], name='layer_2')\n",
    "\n",
    "output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES], \n",
    "                      bias_dim=[NR_CLASSES], name='out')\n",
    "\n",
    "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created directories!\n"
     ]
    }
   ],
   "source": [
    "# Folder for Tensorboard\n",
    "\n",
    "folder_name = f'{model_name} at {strftime(\"%H:%M\")}'\n",
    "directory = os.path.join(LOGGING_PATH, folder_name)\n",
    "\n",
    "try:\n",
    "    os.makedirs(directory)\n",
    "except OSError as exception:\n",
    "    print(exception.strerror)\n",
    "else:\n",
    "    print('Successfully created directories!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimisation & Metrics\n",
    "\n",
    "- Defining Loss Function\n",
    "- Defining Optimizer\n",
    "- Accuracy Metric\n",
    "- Check Input Images in Tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss_calc'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy_calc'):\n",
    "    correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('performance'):\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('cost', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('show_image'):\n",
    "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
    "    tf.summary.image('image_input', x_image, max_outputs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Session\n",
    "\n",
    "- Setup Filewriter and Merge Summaries\n",
    "- Initialise all the variables\n",
    "- Batching the Data\n",
    "- Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "train_writer = tf.summary.FileWriter(directory + '/train')\n",
    "train_writer.add_graph(sess.graph)\n",
    "\n",
    "validation_writer = tf.summary.FileWriter(directory + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 21:42:34.570985: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = y_train.shape[0]\n",
    "nr_iterations = int(num_examples/size_of_batch)\n",
    "\n",
    "index_in_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t| Training Accuracy = 0.7620000243186951\n",
      "Epoch 1 \t| Training Accuracy = 0.8159999847412109\n",
      "Epoch 2 \t| Training Accuracy = 0.8389999866485596\n",
      "Epoch 3 \t| Training Accuracy = 0.8399999737739563\n",
      "Epoch 4 \t| Training Accuracy = 0.8500000238418579\n",
      "Epoch 5 \t| Training Accuracy = 0.8529999852180481\n",
      "Epoch 6 \t| Training Accuracy = 0.8529999852180481\n",
      "Epoch 7 \t| Training Accuracy = 0.8600000143051147\n",
      "Epoch 8 \t| Training Accuracy = 0.949999988079071\n",
      "Epoch 9 \t| Training Accuracy = 0.9490000009536743\n",
      "Epoch 10 \t| Training Accuracy = 0.9580000042915344\n",
      "Epoch 11 \t| Training Accuracy = 0.9599999785423279\n",
      "Epoch 12 \t| Training Accuracy = 0.9610000252723694\n",
      "Epoch 13 \t| Training Accuracy = 0.9610000252723694\n",
      "Epoch 14 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 15 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 16 \t| Training Accuracy = 0.9710000157356262\n",
      "Epoch 17 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 18 \t| Training Accuracy = 0.9639999866485596\n",
      "Epoch 19 \t| Training Accuracy = 0.9729999899864197\n",
      "Epoch 20 \t| Training Accuracy = 0.9649999737739563\n",
      "Epoch 21 \t| Training Accuracy = 0.9589999914169312\n",
      "Epoch 22 \t| Training Accuracy = 0.968999981880188\n",
      "Epoch 23 \t| Training Accuracy = 0.972000002861023\n",
      "Epoch 24 \t| Training Accuracy = 0.9700000286102295\n",
      "Epoch 25 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 26 \t| Training Accuracy = 0.9700000286102295\n",
      "Epoch 27 \t| Training Accuracy = 0.9739999771118164\n",
      "Epoch 28 \t| Training Accuracy = 0.9660000205039978\n",
      "Epoch 29 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 30 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 31 \t| Training Accuracy = 0.9729999899864197\n",
      "Epoch 32 \t| Training Accuracy = 0.968999981880188\n",
      "Epoch 33 \t| Training Accuracy = 0.9739999771118164\n",
      "Epoch 34 \t| Training Accuracy = 0.9710000157356262\n",
      "Epoch 35 \t| Training Accuracy = 0.9710000157356262\n",
      "Epoch 36 \t| Training Accuracy = 0.9750000238418579\n",
      "Epoch 37 \t| Training Accuracy = 0.9700000286102295\n",
      "Epoch 38 \t| Training Accuracy = 0.9779999852180481\n",
      "Epoch 39 \t| Training Accuracy = 0.9679999947547913\n",
      "Epoch 40 \t| Training Accuracy = 0.9710000157356262\n",
      "Epoch 41 \t| Training Accuracy = 0.9779999852180481\n",
      "Epoch 42 \t| Training Accuracy = 0.9710000157356262\n",
      "Epoch 43 \t| Training Accuracy = 0.9769999980926514\n",
      "Epoch 44 \t| Training Accuracy = 0.9760000109672546\n",
      "Epoch 45 \t| Training Accuracy = 0.9779999852180481\n",
      "Epoch 46 \t| Training Accuracy = 0.9729999899864197\n",
      "Epoch 47 \t| Training Accuracy = 0.9789999723434448\n",
      "Epoch 48 \t| Training Accuracy = 0.9739999771118164\n",
      "Epoch 49 \t| Training Accuracy = 0.9800000190734863\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    # ============= Training Dataset =========\n",
    "    for i in range(nr_iterations):\n",
    "        \n",
    "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_train, labels=y_train)\n",
    "        \n",
    "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dictionary)\n",
    "        \n",
    "    \n",
    "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict=feed_dictionary)\n",
    "        \n",
    "    train_writer.add_summary(s, epoch)\n",
    "    \n",
    "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
    "    \n",
    "    # ================== Validation ======================\n",
    "    \n",
    "    summary = sess.run(fetches=merged_summary, feed_dict={X:x_val, Y:y_val})\n",
    "    validation_writer.add_summary(summary, epoch)\n",
    "\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('data/test_img.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw = img.convert('L')\n",
    "img_array = np.invert(bw)\n",
    "\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = img_array.ravel()\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image is [2]\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})\n",
    "print(f'Prediction for test image is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 95.64%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test, Y:y_test})\n",
    "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = saver.save(sess, \"model/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: export_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "trained_checkpoint_prefix = 'model/model.ckpt'\n",
    "export_dir = os.path.join('export_model')\n",
    "\n",
    "graph = tf.Graph()\n",
    "with tf.compat.v1.Session(graph=graph) as sess:\n",
    "    # Restore from checkpoint\n",
    "    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')\n",
    "    loader.restore(sess, trained_checkpoint_prefix)\n",
    "\n",
    "    # Export checkpoint to SavedModel\n",
    "    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         [tf.saved_model.TRAINING, tf.saved_model.SERVING],\n",
    "                                         strip_default_attrs=True)\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index (0) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb Cell 60'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(modelPath)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=5'>6</a>\u001b[0m     tfjs\u001b[39m.\u001b[39mconverters\u001b[39m.\u001b[39msave_keras_model(model, \u001b[39m\"\u001b[39m\u001b[39mtfjsmodel\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=7'>8</a>\u001b[0m importModel(\u001b[39m\"\u001b[39;49m\u001b[39mexport_model/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb Cell 60'\u001b[0m in \u001b[0;36mimportModel\u001b[0;34m(modelPath)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimportModel\u001b[39m(modelPath):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(modelPath)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bevanventer/Desktop/Projects/Python/DS-Hand-Write-Project/model/eda.ipynb#ch0000064?line=5'>6</a>\u001b[0m     tfjs\u001b[39m.\u001b[39mconverters\u001b[39m.\u001b[39msave_keras_model(model, \u001b[39m\"\u001b[39m\u001b[39mtfjsmodel\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py:227\u001b[0m, in \u001b[0;36m_generate_object_paths\u001b[0;34m(object_graph_def)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py?line=224'>225</a>\u001b[0m current_node \u001b[39m=\u001b[39m nodes_to_visit\u001b[39m.\u001b[39mpop()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py?line=225'>226</a>\u001b[0m current_path \u001b[39m=\u001b[39m paths[current_node]\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py?line=226'>227</a>\u001b[0m \u001b[39mfor\u001b[39;00m reference \u001b[39min\u001b[39;00m object_graph_def\u001b[39m.\u001b[39;49mnodes[current_node]\u001b[39m.\u001b[39mchildren:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py?line=227'>228</a>\u001b[0m   \u001b[39mif\u001b[39;00m reference\u001b[39m.\u001b[39mnode_id \u001b[39min\u001b[39;00m paths:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/untitled/lib/python3.10/site-packages/keras/saving/saved_model/load.py?line=228'>229</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index (0) out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "def importModel(modelPath):\n",
    "    model = keras.models.load_model(modelPath)\n",
    "    tfjs.converters.save_keras_model(model, \"tfjsmodel\")\n",
    "\n",
    "importModel(\"export_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset for the Next Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "validation_writer.close()\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aa441d0507601915f9dd565824a7f6ae81e35994691cbfb1b2ff9baf965ea56"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('untitled')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
